/**
 * Performance tests for file operations and response times
 * Tests file serving speed, concurrency, and resource usage
 */

import { test, expect } from '@playwright/test'\nimport fs from 'fs/promises'\nimport path from 'path'\n\n// Test configuration\nconst TEST_BASE_URL = process.env.TEST_BASE_URL || 'http://localhost:3000'\nconst PERFORMANCE_THRESHOLDS = {\n  SMALL_FILE_RESPONSE: 500, // ms\n  LARGE_FILE_RESPONSE: 2000, // ms\n  CONCURRENT_REQUESTS: 5000, // ms\n  MEMORY_USAGE_MB: 100, // MB\n  CPU_USAGE_PERCENT: 80 // %\n}\n\ninterface PerformanceMetrics {\n  responseTime: number\n  contentLength: number\n  throughput: number\n  memoryUsage?: number\n  cpuUsage?: number\n}\n\ntest.describe('File Operations Performance Tests', () => {\n  let testFiles: { name: string; size: number; path: string }[] = []\n\n  test.beforeAll(async () => {\n    // Create test files of various sizes\n    const uploadsDir = path.join(process.cwd(), 'uploads', '2024', '12')\n    \n    try {\n      await fs.mkdir(uploadsDir, { recursive: true })\n\n      // Small file (1KB)\n      const smallContent = 'x'.repeat(1024)\n      await fs.writeFile(path.join(uploadsDir, 'small-1kb.txt'), smallContent)\n      testFiles.push({ name: 'small-1kb.txt', size: 1024, path: '2024/12/small-1kb.txt' })\n\n      // Medium file (100KB)\n      const mediumContent = 'y'.repeat(100 * 1024)\n      await fs.writeFile(path.join(uploadsDir, 'medium-100kb.txt'), mediumContent)\n      testFiles.push({ name: 'medium-100kb.txt', size: 100 * 1024, path: '2024/12/medium-100kb.txt' })\n\n      // Large file (1MB)\n      const largeContent = 'z'.repeat(1024 * 1024)\n      await fs.writeFile(path.join(uploadsDir, 'large-1mb.txt'), largeContent)\n      testFiles.push({ name: 'large-1mb.txt', size: 1024 * 1024, path: '2024/12/large-1mb.txt' })\n\n      // Very large file (5MB)\n      const veryLargeContent = 'a'.repeat(5 * 1024 * 1024)\n      await fs.writeFile(path.join(uploadsDir, 'very-large-5mb.txt'), veryLargeContent)\n      testFiles.push({ name: 'very-large-5mb.txt', size: 5 * 1024 * 1024, path: '2024/12/very-large-5mb.txt' })\n\n      console.log(`Created ${testFiles.length} test files for performance testing`)\n    } catch (error) {\n      console.warn('Could not create test files:', error)\n    }\n  })\n\n  test.afterAll(async () => {\n    // Cleanup test files\n    try {\n      for (const file of testFiles) {\n        const filePath = path.join(process.cwd(), 'uploads', file.path)\n        await fs.unlink(filePath).catch(() => {}) // Ignore errors\n      }\n    } catch (error) {\n      console.warn('Could not clean up test files:', error)\n    }\n  })\n\n  test.describe('Individual File Response Times', () => {\n    testFiles.forEach(file => {\n      test(`should serve ${file.name} within performance threshold`, async ({ page }) => {\n        const startTime = Date.now()\n\n        const response = await page.request.get(`${TEST_BASE_URL}/api/files/${file.path}`)\n        \n        const responseTime = Date.now() - startTime\n        const contentLength = parseInt(response.headers()['content-length'] || '0', 10)\n\n        expect(response.status()).toBe(200)\n        expect(contentLength).toBe(file.size)\n\n        // Performance assertions\n        if (file.size <= 10 * 1024) { // Small files (â‰¤10KB)\n          expect(responseTime).toBeLessThan(PERFORMANCE_THRESHOLDS.SMALL_FILE_RESPONSE)\n        } else { // Large files\n          expect(responseTime).toBeLessThan(PERFORMANCE_THRESHOLDS.LARGE_FILE_RESPONSE)\n        }\n\n        // Calculate throughput (bytes/second)\n        const throughput = (file.size / responseTime) * 1000\n        expect(throughput).toBeGreaterThan(1024) // At least 1KB/s\n\n        console.log(`${file.name}: ${responseTime}ms, ${Math.round(throughput / 1024)}KB/s`)\n      })\n    })\n\n    test('should serve HEAD requests faster than GET requests', async ({ page }) => {\n      const testFile = testFiles.find(f => f.name.includes('medium')) || testFiles[0]\n\n      // Measure HEAD request\n      const headStart = Date.now()\n      const headResponse = await page.request.head(`${TEST_BASE_URL}/api/files/${testFile.path}`)\n      const headTime = Date.now() - headStart\n\n      // Measure GET request\n      const getStart = Date.now()\n      const getResponse = await page.request.get(`${TEST_BASE_URL}/api/files/${testFile.path}`)\n      const getTime = Date.now() - getStart\n\n      expect(headResponse.status()).toBe(200)\n      expect(getResponse.status()).toBe(200)\n      expect(headTime).toBeLessThan(getTime)\n      expect(headTime).toBeLessThan(PERFORMANCE_THRESHOLDS.SMALL_FILE_RESPONSE)\n\n      console.log(`HEAD: ${headTime}ms, GET: ${getTime}ms`)\n    })\n  })\n\n  test.describe('Concurrent Request Performance', () => {\n    test('should handle multiple concurrent requests efficiently', async ({ browser }) => {\n      const context = await browser.newContext()\n      const concurrencyLevels = [5, 10, 20]\n      const testFile = testFiles.find(f => f.name.includes('small')) || testFiles[0]\n\n      for (const concurrency of concurrencyLevels) {\n        const startTime = Date.now()\n        \n        // Create multiple concurrent requests\n        const requests = Array.from({ length: concurrency }, async () => {\n          const page = await context.newPage()\n          const response = await page.request.get(`${TEST_BASE_URL}/api/files/${testFile.path}`)\n          await page.close()\n          return response\n        })\n\n        const responses = await Promise.all(requests)\n        const totalTime = Date.now() - startTime\n\n        // Verify all requests succeeded\n        responses.forEach(response => {\n          expect(response.status()).toBe(200)\n        })\n\n        // Performance assertions\n        expect(totalTime).toBeLessThan(PERFORMANCE_THRESHOLDS.CONCURRENT_REQUESTS)\n\n        const avgResponseTime = totalTime / concurrency\n        console.log(`Concurrency ${concurrency}: Total ${totalTime}ms, Avg ${avgResponseTime.toFixed(2)}ms per request`)\n      }\n\n      await context.close()\n    })\n\n    test('should maintain performance under sustained load', async ({ browser }) => {\n      const context = await browser.newContext()\n      const testFile = testFiles.find(f => f.name.includes('small')) || testFiles[0]\n      const loadDuration = 30000 // 30 seconds\n      const requestInterval = 100 // ms between requests\n      const maxConcurrentRequests = 10\n\n      const startTime = Date.now()\n      const results: PerformanceMetrics[] = []\n      let activeRequests = 0\n\n      const makeRequest = async (): Promise<PerformanceMetrics> => {\n        const requestStart = Date.now()\n        const page = await context.newPage()\n        \n        try {\n          const response = await page.request.get(`${TEST_BASE_URL}/api/files/${testFile.path}`)\n          const responseTime = Date.now() - requestStart\n          const contentLength = parseInt(response.headers()['content-length'] || '0', 10)\n          \n          return {\n            responseTime,\n            contentLength,\n            throughput: (contentLength / responseTime) * 1000\n          }\n        } finally {\n          await page.close()\n          activeRequests--\n        }\n      }\n\n      // Run sustained load test\n      while (Date.now() - startTime < loadDuration) {\n        if (activeRequests < maxConcurrentRequests) {\n          activeRequests++\n          makeRequest().then(result => {\n            results.push(result)\n          }).catch(error => {\n            console.warn('Request failed:', error.message)\n            activeRequests--\n          })\n        }\n\n        await new Promise(resolve => setTimeout(resolve, requestInterval))\n      }\n\n      // Wait for remaining requests to complete\n      while (activeRequests > 0) {\n        await new Promise(resolve => setTimeout(resolve, 100))\n      }\n\n      await context.close()\n\n      // Analyze results\n      expect(results.length).toBeGreaterThan(100) // Should have processed many requests\n\n      const avgResponseTime = results.reduce((sum, r) => sum + r.responseTime, 0) / results.length\n      const maxResponseTime = Math.max(...results.map(r => r.responseTime))\n      const minResponseTime = Math.min(...results.map(r => r.responseTime))\n\n      console.log(`Sustained load test: ${results.length} requests`)\n      console.log(`Response times - Avg: ${avgResponseTime.toFixed(2)}ms, Min: ${minResponseTime}ms, Max: ${maxResponseTime}ms`)\n\n      // Performance assertions\n      expect(avgResponseTime).toBeLessThan(PERFORMANCE_THRESHOLDS.SMALL_FILE_RESPONSE)\n      expect(maxResponseTime).toBeLessThan(PERFORMANCE_THRESHOLDS.SMALL_FILE_RESPONSE * 3) // Allow some variance\n    })\n  })\n\n  test.describe('Content Type and Caching Performance', () => {\n    test('should cache static files effectively', async ({ page }) => {\n      const testFile = testFiles.find(f => f.name.includes('medium')) || testFiles[0]\n\n      // First request (cold cache)\n      const firstStart = Date.now()\n      const firstResponse = await page.request.get(`${TEST_BASE_URL}/api/files/${testFile.path}`)\n      const firstTime = Date.now() - firstStart\n\n      expect(firstResponse.status()).toBe(200)\n      expect(firstResponse.headers()['cache-control']).toContain('max-age')\n\n      // Second request (should be faster due to potential caching)\n      const secondStart = Date.now()\n      const secondResponse = await page.request.get(`${TEST_BASE_URL}/api/files/${testFile.path}`)\n      const secondTime = Date.now() - secondStart\n\n      expect(secondResponse.status()).toBe(200)\n\n      console.log(`Cache test - First: ${firstTime}ms, Second: ${secondTime}ms`)\n\n      // Note: Actual cache effectiveness depends on server configuration\n      // This test mainly verifies that caching headers are set correctly\n    })\n\n    test('should detect content types quickly', async ({ page }) => {\n      const contentTypeTests = [\n        { file: 'test.jpg', expectedType: 'image/jpeg' },\n        { file: 'test.png', expectedType: 'image/png' },\n        { file: 'test.pdf', expectedType: 'application/pdf' },\n        { file: 'test.txt', expectedType: 'text/plain' }\n      ]\n\n      // Create small test files with different extensions\n      const uploadsDir = path.join(process.cwd(), 'uploads', '2024', '12')\n      \n      for (const test of contentTypeTests) {\n        try {\n          await fs.writeFile(path.join(uploadsDir, test.file), 'test content')\n        } catch (error) {\n          console.warn(`Could not create ${test.file}:`, error)\n          continue\n        }\n\n        const startTime = Date.now()\n        const response = await page.request.head(`${TEST_BASE_URL}/api/files/2024/12/${test.file}`)\n        const responseTime = Date.now() - startTime\n\n        expect(response.status()).toBe(200)\n        expect(response.headers()['content-type']).toBe(test.expectedType)\n        expect(responseTime).toBeLessThan(200) // Content type detection should be fast\n\n        // Cleanup\n        await fs.unlink(path.join(uploadsDir, test.file)).catch(() => {})\n      }\n    })\n  })\n\n  test.describe('Error Handling Performance', () => {\n    test('should handle 404 errors quickly', async ({ page }) => {\n      const nonExistentFiles = [\n        'missing-file-1.txt',\n        'missing-file-2.pdf',\n        'missing-file-3.jpg'\n      ]\n\n      for (const filename of nonExistentFiles) {\n        const startTime = Date.now()\n        const response = await page.request.get(`${TEST_BASE_URL}/api/files/2024/12/${filename}`)\n        const responseTime = Date.now() - startTime\n\n        expect(response.status()).toBe(404)\n        expect(responseTime).toBeLessThan(500) // 404 responses should be fast\n\n        console.log(`404 response for ${filename}: ${responseTime}ms`)\n      }\n    })\n\n    test('should handle malformed requests without degrading performance', async ({ page }) => {\n      const malformedRequests = [\n        '/api/files/', // Empty path\n        '/api/files/../../../etc/passwd', // Path traversal\n        '/api/files/' + 'a'.repeat(1000), // Very long path\n        '/api/files/~/sensitive' // Tilde path\n      ]\n\n      for (const url of malformedRequests) {\n        const startTime = Date.now()\n        const response = await page.request.get(`${TEST_BASE_URL}${url}`)\n        const responseTime = Date.now() - startTime\n\n        expect(response.status()).toBe(400)\n        expect(responseTime).toBeLessThan(300) // Error responses should be very fast\n\n        console.log(`Malformed request response: ${responseTime}ms`)\n      }\n    })\n  })\n\n  test.describe('S3 Fallback Performance', () => {\n    test('should handle S3 fallback with acceptable latency', async ({ page }) => {\n      // Test assumes S3 is configured but files don't exist locally\n      const s3OnlyFile = 'hypothetical-s3-file.txt'\n\n      const startTime = Date.now()\n      const response = await page.request.get(`${TEST_BASE_URL}/api/files/2024/12/${s3OnlyFile}`)\n      const responseTime = Date.now() - startTime\n\n      // This will likely return 404 in test environment, but should still be reasonably fast\n      expect([200, 404, 500]).toContain(response.status())\n      expect(responseTime).toBeLessThan(5000) // S3 fallback might be slower but should not hang\n\n      console.log(`S3 fallback test: ${responseTime}ms (status: ${response.status()})`)\n    })\n  })\n\n  test.describe('Memory and Resource Usage', () => {\n    test('should not leak memory during file operations', async ({ browser }) => {\n      // This is a basic test - in a real environment you'd use more sophisticated memory monitoring\n      const context = await browser.newContext()\n      const testFile = testFiles.find(f => f.name.includes('large')) || testFiles[0]\n\n      // Perform many file operations\n      const iterations = 50\n      const startTime = Date.now()\n\n      for (let i = 0; i < iterations; i++) {\n        const page = await context.newPage()\n        const response = await page.request.get(`${TEST_BASE_URL}/api/files/${testFile.path}`)\n        expect(response.status()).toBe(200)\n        await page.close()\n\n        // Add small delay to prevent overwhelming the server\n        if (i % 10 === 0) {\n          await new Promise(resolve => setTimeout(resolve, 100))\n        }\n      }\n\n      const totalTime = Date.now() - startTime\n      const avgTimePerRequest = totalTime / iterations\n\n      await context.close()\n\n      console.log(`Memory test: ${iterations} iterations, avg ${avgTimePerRequest.toFixed(2)}ms per request`)\n\n      // The test mainly ensures no crashes or hanging - actual memory monitoring would require additional tools\n      expect(avgTimePerRequest).toBeLessThan(1000) // Should maintain reasonable performance\n    })\n  })\n\n  test.describe('Analytics Performance', () => {\n    test('should not significantly impact response time when logging analytics', async ({ page }) => {\n      const testFile = testFiles.find(f => f.name.includes('small')) || testFiles[0]\n      const teacherId = 'perf_test_teacher'\n      const sessionId = 'perf_test_session'\n\n      // Request without analytics\n      const startTimeNoAnalytics = Date.now()\n      const responseNoAnalytics = await page.request.get(`${TEST_BASE_URL}/api/files/${testFile.path}`)\n      const timeNoAnalytics = Date.now() - startTimeNoAnalytics\n\n      // Request with analytics\n      const startTimeWithAnalytics = Date.now()\n      const responseWithAnalytics = await page.request.get(\n        `${TEST_BASE_URL}/api/files/${testFile.path}?teacherId=${teacherId}&sessionId=${sessionId}`\n      )\n      const timeWithAnalytics = Date.now() - startTimeWithAnalytics\n\n      expect(responseNoAnalytics.status()).toBe(200)\n      expect(responseWithAnalytics.status()).toBe(200)\n\n      console.log(`Analytics overhead: Without ${timeNoAnalytics}ms, With ${timeWithAnalytics}ms`)\n\n      // Analytics should not add significant overhead\n      const overhead = timeWithAnalytics - timeNoAnalytics\n      expect(Math.abs(overhead)).toBeLessThan(500) // Allow reasonable variance\n    })\n  })\n})"